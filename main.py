import streamlit as st
from response import generate_response
from summary import generate_summary
from transcribe import generate_transcript

st.set_page_config(layout="wide", page_title="MediaSleuth360", page_icon="üîç")

def display_summary() -> None:
    st.subheader("Media Summary")
    st.write(generate_summary(file))

if not ('file' in st.session_state and 'type' in st.session_state):
    # Welcome message
    st.html("<center><h1>Welcome to MediaSleuth360</h1></center>")

    # Display instructions in an expanded state
    st.expander(":Bold[‚ùóInstructions]", expanded=True).markdown("""
    1. Upload an audio or video file.
    2. The media summary will be displayed below the chatbox.
    3. Type your question in the chatbox about the media content you uploaded.
    4. The AI assistant will respond to your prompt after analyzing the media.
    """)

    st.html("<h3>Upload Media File</h3>")

    # Upload file, only accept one file
    st.session_state.file = file = st.file_uploader(
        "Upload an audio or video file to get started.", 
        accept_multiple_files=False, 
        label_visibility="collapsed"
    )

    if file:
        if file.type.startswith("video") or file.type.startswith("audio"):
            st.session_state.type = file.type
            st.session_state.start_time = 0
            st.rerun()
        else:
            st.error("Please upload a video or audio file.")
else:
    file = st.session_state.file
    start_time = st.session_state.start_time

    st.html("""<div style="background-color: #ffcccc; padding: 10px; border-radius: 5px; text-align: center;">
                <span style="color: red; font-weight: bold;">
                    NOTE: The responses are generated by AI and can be inaccurate. Double verify important info.
                </span>
            </div>""")

    # Create two columns
    left_column, right_column = st.columns((5,2))

    # Left column - Media player
    with left_column:
        # Display media file
        if file.type.startswith("video"):
            st.video(file, start_time=start_time)
        else:
            st.audio(file, start_time=start_time)

        # Media summary
        if file.type.startswith("audio"):
            display_summary()

    # Right column - Chatbox
    with right_column:
        # Chat messages container
        chat_container = st.container(border=True, height=500)

        # initialize st.session_state.messages
        if 'messages' not in st.session_state:
            st.session_state.messages = []

        # Display chat messages from history on app rerun
        with chat_container:
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])

        # Chat input
        if prompt := st.chat_input("What would you like to know about the media?"):
            st.session_state.messages.append({"role": "user", "content": prompt})

            # Display user prompt in chat message container
            with chat_container:
                with st.chat_message("user"):
                    st.markdown(prompt)

            transcript = generate_transcript(file)
            system_prompt = f""""Answer the question based on the context: {transcript}\n\n\
Note: If the prompt is not relevent to the media just reply with 'your question is out of scope.'"""

            # Generate response from AI assistant
            response = generate_response(prompt, system_prompt)

            # Add assistant response to chat history
            st.session_state.messages.append({"role": "assistant", "content": response})

            # Display assistant response in chat message container
            with chat_container:
                with st.chat_message("assistant"):
                    st.markdown(response)

    # Media summary
    if file.type.startswith("video"):
        display_summary()